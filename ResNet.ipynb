{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom __future__ import division\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport six\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport glob\nimport random\n\nnp.random.seed(2016)\nrandom.seed(2016)\n\nfrom keras.models import Model\nfrom keras.layers import Input, Activation, merge, Dense, Flatten\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import gc\nimport sys\n \nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras import applications as apps\nfrom keras import optimizers as opt\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.callbacks import LearningRateScheduler",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b2c0bd28813536dc4f81c15a5e888e6454e5a2e"
      },
      "cell_type": "markdown",
      "source": "## Define Useful Functions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e18d74dae1dfe6bcde1b294c40c3a3d91b9c4af"
      },
      "cell_type": "code",
      "source": "def setup_to_transfer_learn(model, base_model) -> 'model':\n    \"\"\"Setup the models for transfer learning\"\"\"\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    model.compile(\n        Adam(lr=conf['learnr']),    \n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    return model\n ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "436ecce5e9e1ee37ce74339d3455892fc07174ea"
      },
      "cell_type": "code",
      "source": "def setup_to_finetune(model, n) -> 'model':\n    \"\"\"Setup the models for finetunning.\"\"\"\n    # Setting everything bellow n to be not trainable\n    for i, layer in enumerate(model.layers):\n            layer.trainable = i > n\n \n    model.compile(\n        optimizer=opt.SGD(lr=0.0001),\n        momentum=0.9,\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n \n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84594ddf67ba3f47f41f8ad1a2e7685f0f551a63"
      },
      "cell_type": "code",
      "source": "def batch_generator_train(files, batch_size):\n    import numpy\n    number_of_batches = np.ceil(len(files)/batch_size)\n    counter = 0\n    numpy.random.shuffle(files) # shuffles Files in place\n    while True:\n        batch_files = files[batch_size*counter:batch_size*(counter+1)]\n        image_list = []\n        mask_list = []\n        for f in batch_files:\n            image = cv2.imread(f)\n            image = cv2.resize(image, conf['image_shape'])\n\n            cancer_type = f[62:63] # relies on path lengths that is hard coded below\n            if cancer_type == '1':\n                mask = [1, 0, 0]\n            elif cancer_type == '2':\n                mask = [0, 1, 0]\n            else:\n                mask = [0, 0, 1]\n\n            image_list.append(image)\n            mask_list.append(mask)\n        counter += 1\n        image_list = np.array(image_list)\n        mask_list = np.array(mask_list)\n\n        yield image_list, mask_list\n\n        if counter == number_of_batches:\n            random.shuffle(files)\n            counter = 0",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aef1fc4799f85c7faa4e522d1a855bfc4d2df1ae"
      },
      "cell_type": "code",
      "source": "def entire_generator(files):\n    \n    import numpy\n    \n    image_list = []\n    mask_list = []\n    \n    numpy.random.shuffle(files) # shuffles Files in place\n    \n    for f in files:\n        image = cv2.imread(f)\n        image = cv2.resize(image, conf['image_shape'])\n\n        cancer_type = f[62] # relies on path lengths that is hard coded below\n        if cancer_type == '1':\n            mask = [1, 0, 0]\n        elif cancer_type == '2':\n            mask = [0, 1, 0]\n        else:\n            mask = [0, 0, 1]\n\n        image_list.append(image)\n        mask_list.append(mask)\n\n    image_list = np.array(image_list)\n    mask_list = np.array(mask_list)\n    \n    return image_list, mask_list",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6d43c00d495adc2ed7f25417755569ba4f37cac3"
      },
      "cell_type": "markdown",
      "source": "## Main Code"
    },
    {
      "metadata": {
        "_uuid": "4bb94eb67e6e27469805896c39f1eee8deb5c76f"
      },
      "cell_type": "markdown",
      "source": "### Set Parameters"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "699ab2ac58759e80374661151ad4579b16090a3d"
      },
      "cell_type": "code",
      "source": "conf = dict()\n\n# How many patients will be in train and validation set during training. Range: (0; 1)\nconf['train_valid_fraction'] = 0.75\n\n# Batch size for CNN [Depends on GPU and memory available]\nconf['batch_size'] = 32\n\n# Number of epochs for CNN training\nconf['nb_epoch'] = 25\n#conf['nb_epoch'] = 1\n\n# Early stopping. Stop training after epochs without improving on validation\nconf['patience'] = 3\n\n# Shape of image for CNN (Larger the better, but you need to increase CNN as well)\n#conf['image_shape'] = (4160,4128)\n#conf['image_shape'] = (2080,2064)\n#conf['image_shape'] = (1024,1024)\nconf['image_shape'] = (64,64)\n\nconf['learnr'] = 0.005\n\nacc_title = 'Accuracy_ResNet50_FreezeAll_WthDecay'\nloss_title = 'MultiClass_CrossEntropyLoss_ResNet50_FreezeAll_WthDecay'\n\n#imgGen = ImageDataGenerator() # No Augmentation\nimgGen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "daae73c8308d0d605794845ca11c29cd16d3e10b"
      },
      "cell_type": "markdown",
      "source": "### Load and Split Data into Training and Validation"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "4cc5510e87853bec28192c78854bd699286e3db6"
      },
      "cell_type": "code",
      "source": "import glob\nimport numpy as np\n\nfilepaths = []\nfilepaths.append('../input/intel-mobileodt-cervical-cancer-screening/train/Type_1/')\nfilepaths.append('../input/intel-mobileodt-cervical-cancer-screening/train/Type_2/')\nfilepaths.append('../input/intel-mobileodt-cervical-cancer-screening/train/Type_3/')\n\nallFiles = []\n\nfor i, filepath in enumerate(filepaths):\n    files = glob.glob(filepath + '*.jpg')\n    allFiles = allFiles + files\n\ntrain_fraction = 0.75\n\nsplit_point = int(round(train_fraction*len(allFiles)))\n\nnp.random.shuffle(allFiles)\ntrain_list = allFiles[:split_point]\nvalid_list = allFiles[split_point:]\nprint('Train patients: {}'.format(len(train_list)))\nprint('Validation patients: {}'.format(len(valid_list)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d64882e9ac8e276c353e789fe7d63110b57c622c"
      },
      "cell_type": "markdown",
      "source": "### Generate entire list"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d20823d22c8d876fe7cbc3ce956982625e08dff9"
      },
      "cell_type": "code",
      "source": "train_data, train_labels = entire_generator(train_list)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "060cd4fa9dcc97fbbd348a465a1078a9f6889448"
      },
      "cell_type": "markdown",
      "source": "### Create Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a471d3fe314af76b8a394cd2b9d2aa97b05e3d0"
      },
      "cell_type": "code",
      "source": "filename_model_json = 'model.json'\nfilename_model_weights = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbatch_size = conf['batch_size']\nnum_classes = 3\nsteps_train = (30938/256)\nsteps_test = (3596/256)\n \nbase_model = apps.resnet50.ResNet50(include_top=False, \n                                    weights = filename_model_weights, \n                                    pooling = 'avg')\nppf = apps.resnet50.preprocess_input\n \nx = base_model.output\npred = Dense(num_classes, activation='softmax')(x)\nmodel = Model(inputs=base_model.input, outputs=pred)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "03a55fd0051dfe118417eae9ad6de5b5661551fd"
      },
      "cell_type": "code",
      "source": "model = setup_to_transfer_learn(model, base_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b27cf882bb42f1308c2cc9380bccd9ef8ac4e5a"
      },
      "cell_type": "code",
      "source": "from keras import utils \nutils.print_summary(model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7f0523d412a1cecf6dfaad4a2db4128d2ead1157"
      },
      "cell_type": "code",
      "source": "import math\ndef step_decay(epoch):\n    initial_lrate = conf['learnr']\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(drop,  \n           math.floor((1+epoch)/epochs_drop))\n    return lrate",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dcb50a15ff89140c4afd2768a3fd3c4b2df268c0",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "print('Fit model...')\n\nimgGen.fit(train_data)\ngenerator= imgGen.flow(train_data, train_labels, conf['batch_size'])\n\nhistory = model.fit_generator(#generator=batch_generator_train(train_list, conf['batch_size']),\n                          generator,\n                          steps_per_epoch=len(generator)/conf['batch_size'],\n                          epochs=conf['nb_epoch'],\n                          validation_data=batch_generator_train(valid_list, batch_size = conf['batch_size']),\n                          validation_steps=len(valid_list)/conf['batch_size'],\n                          callbacks = [LearningRateScheduler(step_decay)],\n                         )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14f383fc4255f20e30634c13e1e0199ae5d53569"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,10))\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title(acc_title)\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\nplt.savefig(acc_title + '.jpg')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0e01f6a1c6f6aa2a91f02502e3cae8fbeeeb7dc"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(20,10))\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title(loss_title)\nplt.ylabel('Multiclass_crossentropy_loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()\nplt.savefig(loss_title + '.jpg')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efaf9d61fe2f4c34052bba2b3c6ebf351a974a38"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}